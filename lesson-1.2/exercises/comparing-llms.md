# Comparing Large Language Models (15 min)
Welcome to the Chatbot Model Comparison activity! Here, you will compare the output of three different chatbot models. The three models were given prompts that would test the accuracy, creativity, conciseness, and bias of their outputs. Your job is to select the model that performed best in each category. Let's get started!

Complete the activity [here](https://igfnaqfcyl-13589482-i.codehs.me/index.html).  Then edit this page and write down your reflections here:

### Which model did you find performed best overall, and why?
I found model B to perform the best overall due to my own preference. Its responses were the most concise and creative overall, not just on specific categories.

### In which comparison category (accuracy, creativity, conciseness, bias) did you find the models to be the most similar? What about the most different?
I found the models were the most similar in the conciseness category because they kept their responses relatively unbiased and straight to the point. I realized in the creativity topic they were the most different because model C was still very technical and gave an in depth almost philisophical response that didnt feel human. Where as Model B touched on a more simplistic yet still poetically creative response that I think most humans would respond like in the real world.

### Were you surprised by any of the results?
I was not really surprised by any of the results, I just found it intriguing how different the responses were based on the AI model.

### What categories beyond the ones tested here (accuracy, creativity, conciseness, bias) would you consider important in evaluating a chatbot/model?
I consider human like responses as a category, I think its important to present new information and responses in a way that humans will be able to gather and understand easily without having to break down a response beyond whats needed. 
